# === LLM Provider Selection ===
# Set EXACTLY ONE of the following to "True" or "1". If none are True, Ollama will be used by default.
USE_OLLAMA="True"
USE_OPENAI="False"
USE_GEMINI="False"

# === OpenAI Configuration (only needed if USE_OPENAI is True) ===
# Get key from https://platform.openai.com/api-keys
OPENAI_API_KEY="your-openai-api-key-here"
OPENAI_MODEL_NAME="gpt-4" # e.g., gpt-4, gpt-3.5-turbo

# === Ollama Configuration (only needed if USE_OLLAMA is True) ===
# Ensure Ollama is running (e.g., `ollama serve`) and the model is pulled (e.g., `ollama pull llama3`)
OLLAMA_MODEL_NAME="llama3" # e.g., llama3, mistral, llama2
OLLAMA_BASE_URL="http://localhost:11434" # Default Ollama API endpoint

# === Google Gemini Configuration (only needed if USE_GEMINI is True) ===
# Get key from Google AI Studio: https://aistudio.google.com/app/apikey
GEMINI_API_KEY="your-google-api-key-here"
GEMINI_MODEL_NAME="gemini-pro" # e.g., gemini-pro, gemini-1.5-pro-latest

# === Debate Settings (Optional) ===
NUM_REBUTTAL_ROUNDS="2"         # Number of back-and-forth rounds after opening statements
DEBATE_LOG_FILE="debate_log.txt" # File to save debate transcripts
SLEEP_TIME_BETWEEN_TURNS="2"    # Seconds to pause between agent turns for readability
